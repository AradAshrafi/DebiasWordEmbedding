{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolutionary Algorithm for Debiasing Glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness criteria is debiasing only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from cluster import *\n",
    "import codecs\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Glove Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_wv, glove_w2i, glove_vocab = load_embedding('./data/glove.txt')\n",
    "glove_wv = decentralize(glove_wv)\n",
    "glove_wv = normalize(glove_wv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit vocab by excluding words that 'should' have gender bias\n",
    "gender_specific = []\n",
    "\n",
    "with open('./data/male_words.txt') as f:\n",
    "    for l in f:\n",
    "        gender_specific.append(l.strip())\n",
    "with open('./data/female_words.txt') as f:\n",
    "    for l in f:\n",
    "        gender_specific.append(l.strip())\n",
    "\n",
    "with codecs.open('./data/gender_specific_full.json') as f:\n",
    "    gender_specific.extend(json.load(f))\n",
    "    \n",
    "glove_vocab_limit, glove_wv_limit, glove_w2i_limit = limit_vocab(glove_wv, glove_w2i, glove_vocab, exclude=gender_specific)\n",
    "\n",
    "# get most biased words\n",
    "he_vector = glove_wv[glove_w2i['he'], :]\n",
    "she_vector = glove_wv[glove_w2i['she'], :]\n",
    "biased_words = compute_word_bias(glove_wv_limit, glove_w2i_limit, glove_vocab_limit, he_vector, she_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from web.evaluate import evaluate_categorization\n",
    "from web.datasets.categorization import fetch_BLESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bless_data = fetch_BLESS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolutionary Algorithm functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(parent):\n",
    "    '''Mutate one point in the parent's genome ie. small mutation\n",
    "    Input: parent array\n",
    "    Output: child array\n",
    "    '''\n",
    "    \n",
    "    child = np.copy(parent)\n",
    "    \n",
    "    # select one point on the embedding to mutate\n",
    "    i = np.random.randint(0, len(parent))\n",
    "    child[i] += np.random.normal(0, 0.01)\n",
    "    \n",
    "    return child\n",
    "\n",
    "\n",
    "def crossover(parent1, parent2):\n",
    "    '''Create one new child from two parents\n",
    "    Input: two parent arrays\n",
    "    Output: one child array\n",
    "    '''\n",
    "    \n",
    "    child = np.zeros(len(parent1))\n",
    "    \n",
    "    # select random breakpoint on genome and combine parents\n",
    "    i = np.random.randint(1, len(parent1)-1)\n",
    "    child[:i] = parent1[:i]\n",
    "    child[i:] = parent2[i:]\n",
    "    \n",
    "    return child\n",
    "\n",
    "\n",
    "def fitness_based_selection(fitness_list):\n",
    "    '''Given the list of fitness scores for the population, randomly select\n",
    "    and index as if spinning a roulette wheel with space on the wheel proportional\n",
    "    to the individual fitness scores\n",
    "    Input: list of fitness scores\n",
    "    Output: index of selected individual\n",
    "    '''\n",
    "    \n",
    "    index = None\n",
    "    \n",
    "    # randomly place a pointer on roulette wheel\n",
    "    s = sum(fitness_list)\n",
    "    pointer = np.random.random() * s\n",
    "    \n",
    "    # keep adding fitness until it surpasses pointer location\n",
    "    p = 0\n",
    "    for i in range(len(fitness_list)):\n",
    "        p += fitness_list[i]\n",
    "        if p > pointer:\n",
    "            index = i\n",
    "            break\n",
    "            \n",
    "    return index\n",
    "\n",
    "\n",
    "def evaluate_fitness(wv, w2i, vocab):\n",
    "    '''Given an embedding, return the fitness where fitness is a combination\n",
    "    of amount of debiasing and retained utility. We use clustering precision\n",
    "    of most biased words as proxy for bias, so 1-precision is added to fitness.\n",
    "    We use concept categorization as a proxy for utility, so precision is added\n",
    "    to fitness.\n",
    "    Input: word embedding to be evaluated\n",
    "    Output: fitness score'''\n",
    "    \n",
    "    fitness = 0.001\n",
    "    \n",
    "    # restrict vocabulary for clustering\n",
    "    vocab_limit, wv_limit, w2i_limit = limit_vocab(wv, w2i, vocab, exclude=gender_specific)\n",
    "    \n",
    "    # get clustering precision\n",
    "    cluster_precision = my_cluster(wv_limit, w2i_limit, 1, vocab_limit, biased_words, num_biased_words=1000)\n",
    "    fitness += (1 - cluster_precision)\n",
    "    \n",
    "    # build word dictionary\n",
    "    #wv_dict = {}\n",
    "    #for word in vocab:\n",
    "        #wv_dict[word] = wv[w2i[word], :]\n",
    "    \n",
    "    # get categorization precision\n",
    "    #cat_precision = evaluate_categorization(wv_dict, bless_data['X'], bless_data['y'])\n",
    "    #fitness += cat_precision\n",
    "    \n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_size = 100\n",
    "num_gens = 100\n",
    "mutation_rate = 0.25\n",
    "crossover_rate = 0.50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest fitness after 0 generations: 0.003000000000000002\n",
      "Highest fitness after 1 generations: 0.003000000000000002\n",
      "Highest fitness after 2 generations: 0.003000000000000002\n",
      "Highest fitness after 3 generations: 0.0034999999999999467\n",
      "Highest fitness after 4 generations: 0.004000000000000003\n",
      "Highest fitness after 5 generations: 0.004499999999999948\n",
      "Highest fitness after 6 generations: 0.10550000000000004\n",
      "Highest fitness after 7 generations: 0.10699999999999998\n",
      "Highest fitness after 8 generations: 0.10750000000000004\n",
      "Highest fitness after 9 generations: 0.10799999999999998\n",
      "Highest fitness after 10 generations: 0.10799999999999998\n",
      "Highest fitness after 11 generations: 0.10799999999999998\n",
      "Highest fitness after 12 generations: 0.10799999999999998\n",
      "Highest fitness after 13 generations: 0.10799999999999998\n",
      "Highest fitness after 14 generations: 0.10799999999999998\n",
      "Highest fitness after 15 generations: 0.10799999999999998\n",
      "Highest fitness after 16 generations: 0.10799999999999998\n",
      "Highest fitness after 17 generations: 0.10799999999999998\n",
      "Highest fitness after 18 generations: 0.10699999999999998\n",
      "Highest fitness after 19 generations: 0.10699999999999998\n",
      "Highest fitness after 20 generations: 0.10799999999999998\n",
      "Highest fitness after 21 generations: 0.10799999999999998\n",
      "Highest fitness after 22 generations: 0.10699999999999998\n",
      "Highest fitness after 23 generations: 0.10699999999999998\n",
      "Highest fitness after 24 generations: 0.10750000000000004\n",
      "Highest fitness after 25 generations: 0.10750000000000004\n",
      "Highest fitness after 26 generations: 0.10750000000000004\n",
      "Highest fitness after 27 generations: 0.10750000000000004\n",
      "Highest fitness after 28 generations: 0.10699999999999998\n",
      "Highest fitness after 29 generations: 0.10699999999999998\n",
      "Highest fitness after 30 generations: 0.10699999999999998\n",
      "Highest fitness after 31 generations: 0.10699999999999998\n",
      "Highest fitness after 32 generations: 0.10750000000000004\n",
      "Highest fitness after 33 generations: 0.10750000000000004\n",
      "Highest fitness after 34 generations: 0.10750000000000004\n",
      "Highest fitness after 35 generations: 0.10750000000000004\n",
      "Highest fitness after 36 generations: 0.10750000000000004\n",
      "Highest fitness after 37 generations: 0.10750000000000004\n",
      "Highest fitness after 38 generations: 0.10750000000000004\n",
      "Highest fitness after 39 generations: 0.10750000000000004\n",
      "Highest fitness after 40 generations: 0.10750000000000004\n",
      "Highest fitness after 41 generations: 0.10750000000000004\n",
      "Highest fitness after 42 generations: 0.10750000000000004\n",
      "Highest fitness after 43 generations: 0.10750000000000004\n",
      "Highest fitness after 44 generations: 0.10750000000000004\n",
      "Highest fitness after 45 generations: 0.10750000000000004\n",
      "Highest fitness after 46 generations: 0.10750000000000004\n",
      "Highest fitness after 47 generations: 0.10750000000000004\n",
      "Highest fitness after 48 generations: 0.10750000000000004\n",
      "Highest fitness after 49 generations: 0.10750000000000004\n",
      "Highest fitness after 50 generations: 0.10750000000000004\n",
      "Highest fitness after 51 generations: 0.10750000000000004\n",
      "Highest fitness after 52 generations: 0.10750000000000004\n",
      "Highest fitness after 53 generations: 0.10750000000000004\n",
      "Highest fitness after 54 generations: 0.10750000000000004\n",
      "Highest fitness after 55 generations: 0.10750000000000004\n",
      "Highest fitness after 56 generations: 0.10750000000000004\n",
      "Highest fitness after 57 generations: 0.10750000000000004\n",
      "Highest fitness after 58 generations: 0.10750000000000004\n",
      "Highest fitness after 59 generations: 0.10750000000000004\n",
      "Highest fitness after 60 generations: 0.10750000000000004\n",
      "Highest fitness after 61 generations: 0.10750000000000004\n",
      "Highest fitness after 62 generations: 0.10750000000000004\n",
      "Highest fitness after 63 generations: 0.10750000000000004\n",
      "Highest fitness after 64 generations: 0.10750000000000004\n",
      "Highest fitness after 65 generations: 0.10750000000000004\n",
      "Highest fitness after 66 generations: 0.10750000000000004\n",
      "Highest fitness after 67 generations: 0.10750000000000004\n",
      "Highest fitness after 68 generations: 0.10750000000000004\n",
      "Highest fitness after 69 generations: 0.10750000000000004\n",
      "Highest fitness after 70 generations: 0.10750000000000004\n",
      "Highest fitness after 71 generations: 0.10750000000000004\n",
      "Highest fitness after 72 generations: 0.10799999999999998\n",
      "Highest fitness after 73 generations: 0.10750000000000004\n",
      "Highest fitness after 74 generations: 0.10750000000000004\n",
      "Highest fitness after 75 generations: 0.10750000000000004\n",
      "Highest fitness after 76 generations: 0.10750000000000004\n",
      "Highest fitness after 77 generations: 0.10750000000000004\n",
      "Highest fitness after 78 generations: 0.10750000000000004\n",
      "Highest fitness after 79 generations: 0.10750000000000004\n",
      "Highest fitness after 80 generations: 0.10750000000000004\n",
      "Highest fitness after 81 generations: 0.10750000000000004\n",
      "Highest fitness after 82 generations: 0.10799999999999998\n",
      "Highest fitness after 83 generations: 0.10750000000000004\n",
      "Highest fitness after 84 generations: 0.10750000000000004\n",
      "Highest fitness after 85 generations: 0.10750000000000004\n",
      "Highest fitness after 86 generations: 0.10750000000000004\n",
      "Highest fitness after 87 generations: 0.10750000000000004\n",
      "Highest fitness after 88 generations: 0.10750000000000004\n",
      "Highest fitness after 89 generations: 0.10750000000000004\n",
      "Highest fitness after 90 generations: 0.10750000000000004\n",
      "Highest fitness after 91 generations: 0.10750000000000004\n",
      "Highest fitness after 92 generations: 0.10750000000000004\n",
      "Highest fitness after 93 generations: 0.10750000000000004\n",
      "Highest fitness after 94 generations: 0.10750000000000004\n",
      "Highest fitness after 95 generations: 0.10799999999999998\n",
      "Highest fitness after 96 generations: 0.10750000000000004\n",
      "Highest fitness after 97 generations: 0.10750000000000004\n",
      "Highest fitness after 98 generations: 0.10750000000000004\n",
      "Highest fitness after 99 generations: 0.10750000000000004\n",
      "Highest fitness after 100 generations: 0.10750000000000004\n"
     ]
    }
   ],
   "source": [
    "# initialize population and evaluate fitness\n",
    "population = np.random.normal(1.0, 0.1, (pop_size, 300))\n",
    "fitnesses = []\n",
    "for i in range(pop_size):\n",
    "    # multiply word vectors by individual genome to get modified embedding\n",
    "    modified_wv = glove_wv * population[i]\n",
    "    fitness_i = evaluate_fitness(modified_wv, glove_w2i, glove_vocab)\n",
    "    fitnesses.append(fitness_i)\n",
    "print('Highest fitness after 0 generations:', max(fitnesses))\n",
    "\n",
    "# iterate through generations\n",
    "for gen in range(num_gens):\n",
    "    # create array for new population\n",
    "    new_population = np.zeros(population.shape)\n",
    "    new_fitnesses = []\n",
    "    # need to create pop_size children for next generation\n",
    "    for i in range (pop_size):\n",
    "        # select parent based on fitness\n",
    "        index = fitness_based_selection(fitnesses)\n",
    "        # random crossover\n",
    "        if np.random.random() < crossover_rate:\n",
    "            # select second parent\n",
    "            index2 = fitness_based_selection(fitnesses)\n",
    "            # combine both parents to create child\n",
    "            new_population[i] = crossover(population[index], population[index2])\n",
    "        else:\n",
    "            # if no crossover, parent simply propogates to next gen\n",
    "            new_population[i] = population[index]\n",
    "        # random mutation\n",
    "        if np.random.random() < mutation_rate:\n",
    "            new_population[i] = mutation(new_population[i])\n",
    "        # evaluate fitness\n",
    "        modified_wv = glove_wv * new_population[i]\n",
    "        fitness_i = evaluate_fitness(modified_wv, glove_w2i, glove_vocab)\n",
    "        new_fitnesses.append(fitness_i)\n",
    "    population = new_population\n",
    "    fitnesses = new_fitnesses\n",
    "    print('Highest fitness after {} generations: {}'.format(gen+1, max(fitnesses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate fittest individual on bias and utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.argmax(fitnesses)\n",
    "modified_wv = glove_wv * population[i]\n",
    "\n",
    "# restrict vocabulary for clustering\n",
    "vocab_limit, wv_limit, w2i_limit = limit_vocab(modified_wv, glove_w2i, glove_vocab, exclude=gender_specific)\n",
    "    \n",
    "# get clustering precision\n",
    "cluster_precision = my_cluster(wv_limit, w2i_limit, 1, vocab_limit, biased_words, num_biased_words=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8935\n"
     ]
    }
   ],
   "source": [
    "print(cluster_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build word dictionary\n",
    "wv_dict = {}\n",
    "for word in glove_vocab:\n",
    "    wv_dict[word] = modified_wv[glove_w2i[word], :]\n",
    "    \n",
    "# get categorization precision\n",
    "cat_precision = evaluate_categorization(wv_dict, bless_data['X'], bless_data['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8250000000000001\n"
     ]
    }
   ],
   "source": [
    "print(cat_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
