{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding Evaluations\n",
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from cluster import *\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load regular glove\n",
    "glove_wv, glove_w2i, glove_vocab = load_embedding('data/glove.txt')\n",
    "\n",
    "# load hard debiased glove\n",
    "hd_glove_wv, hd_glove_w2i, hd_glove_vocab = load_embedding('data/hard_debias.txt')\n",
    "\n",
    "# load double hard debiased glove\n",
    "#dbl_glove_wv, dbl_glove_w2i, dbl_glove_vocab = load_embedding('data/double_hard_glove.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322636\n",
      "322636\n"
     ]
    }
   ],
   "source": [
    "print(len(glove_wv))\n",
    "print(len(hd_glove_wv))\n",
    "#print(len(dbl_glove_wv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WEAT test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load word lists for tests\n",
    "# start with the male and female names\n",
    "A = [name.lower() for name in WEAT_words['A']]\n",
    "B = [name.lower() for name in WEAT_words['B']]\n",
    "# career and family\n",
    "C = WEAT_words['C']\n",
    "D = WEAT_words['D']\n",
    "# math and arts\n",
    "E = WEAT_words['E']\n",
    "F = WEAT_words['F']\n",
    "# science and arts\n",
    "G = WEAT_words['G']\n",
    "H = WEAT_words['H']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Career and Family\n",
      "1.8440745886996364\n",
      "num of samples 12870\n",
      "0.0\n",
      "Math and Arts\n",
      "0.7598566596555253\n",
      "num of samples 12870\n",
      "0.06775446775446775\n",
      "Science and Arts\n",
      "1.0550881121697777\n",
      "num of samples 12870\n",
      "0.014063714063714063\n"
     ]
    }
   ],
   "source": [
    "# calculate effect size and p value for career and family\n",
    "print('Career and Family')\n",
    "print(effect_size(A, B, C, D, glove_wv, glove_w2i, glove_vocab))\n",
    "print(p_value_test(A, B, C, D, glove_wv, glove_w2i, glove_vocab))\n",
    "\n",
    "# calculate effect size and p value for math and arts\n",
    "print('Math and Arts')\n",
    "print(effect_size(A, B, E, F, glove_wv, glove_w2i, glove_vocab))\n",
    "print(p_value_test(A, B, E, F, glove_wv, glove_w2i, glove_vocab))\n",
    "\n",
    "# calculate effect size and p value for science and arts\n",
    "print('Science and Arts')\n",
    "print(effect_size(A, B, G, H, glove_wv, glove_w2i, glove_vocab))\n",
    "print(p_value_test(A, B, G, H, glove_wv, glove_w2i, glove_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard Debias Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Career and Family\n",
      "1.6177007410709874\n",
      "num of samples 12870\n",
      "7.77000777000777e-05\n",
      "Math and Arts\n",
      "0.1489070026968469\n",
      "num of samples 12870\n",
      "0.3857031857031857\n",
      "Science and Arts\n",
      "0.08429122526252406\n",
      "num of samples 12870\n",
      "0.43496503496503497\n"
     ]
    }
   ],
   "source": [
    "# calculate effect size and p value for career and family\n",
    "print('Career and Family')\n",
    "print(effect_size(A, B, C, D, hd_glove_wv, hd_glove_w2i, hd_glove_vocab))\n",
    "print(p_value_test(A, B, C, D, hd_glove_wv, hd_glove_w2i, hd_glove_vocab))\n",
    "\n",
    "# calculate effect size and p value for math and arts\n",
    "print('Math and Arts')\n",
    "print(effect_size(A, B, E, F, hd_glove_wv, hd_glove_w2i, hd_glove_vocab))\n",
    "print(p_value_test(A, B, E, F, hd_glove_wv, hd_glove_w2i, hd_glove_vocab))\n",
    "\n",
    "# calculate effect size and p value for science and arts\n",
    "print('Science and Arts')\n",
    "print(effect_size(A, B, G, H, hd_glove_wv, hd_glove_w2i, hd_glove_vocab))\n",
    "print(p_value_test(A, B, G, H, hd_glove_wv, hd_glove_w2i, hd_glove_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Hard Debias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# calculate effect size and p value for career and family\\nprint('Career and Family')\\nprint(effect_size(A, B, C, D, dbl_glove_wv, dbl_glove_w2i, dbl_glove_vocab))\\nprint(p_value_test(A, B, C, D, dbl_glove_wv, dbl_glove_w2i, dbl_glove_vocab))\\n\\n# calculate effect size and p value for math and arts\\nprint('Math and Arts')\\nprint(effect_size(A, B, E, F, dbl_glove_wv, dbl_glove_w2i, dbl_glove_vocab))\\nprint(p_value_test(A, B, E, F, dbl_glove_wv, dbl_glove_w2i, dbl_glove_vocab))\\n\\n# calculate effect size and p value for science and arts\\nprint('Science and Arts')\\nprint(effect_size(A, B, G, H, dbl_glove_wv, dbl_glove_w2i, dbl_glove_vocab))\\nprint(p_value_test(A, B, G, H, dbl_glove_wv, dbl_glove_w2i, dbl_glove_vocab))\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# calculate effect size and p value for career and family\n",
    "print('Career and Family')\n",
    "print(effect_size(A, B, C, D, dbl_glove_wv, dbl_glove_w2i, dbl_glove_vocab))\n",
    "print(p_value_test(A, B, C, D, dbl_glove_wv, dbl_glove_w2i, dbl_glove_vocab))\n",
    "\n",
    "# calculate effect size and p value for math and arts\n",
    "print('Math and Arts')\n",
    "print(effect_size(A, B, E, F, dbl_glove_wv, dbl_glove_w2i, dbl_glove_vocab))\n",
    "print(p_value_test(A, B, E, F, dbl_glove_wv, dbl_glove_w2i, dbl_glove_vocab))\n",
    "\n",
    "# calculate effect size and p value for science and arts\n",
    "print('Science and Arts')\n",
    "print(effect_size(A, B, G, H, dbl_glove_wv, dbl_glove_w2i, dbl_glove_vocab))\n",
    "print(p_value_test(A, B, G, H, dbl_glove_wv, dbl_glove_w2i, dbl_glove_vocab))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of vocabulary: 47628\n",
      "size of vocabulary: 47628\n"
     ]
    }
   ],
   "source": [
    "# limit vocab by excluding words that 'should' have gender bias\n",
    "gender_specific = []\n",
    "\n",
    "with open('./data/male_words.txt') as f:\n",
    "    for l in f:\n",
    "        gender_specific.append(l.strip())\n",
    "with open('./data/female_words.txt') as f:\n",
    "    for l in f:\n",
    "        gender_specific.append(l.strip())\n",
    "\n",
    "with codecs.open('./data/gender_specific_full.json') as f:\n",
    "    gender_specific.extend(json.load(f))\n",
    "\n",
    "glove_vocab_limit, glove_wv_limit, glove_w2i_limit = limit_vocab(glove_wv, glove_w2i, glove_vocab, exclude=gender_specific)\n",
    "hd_glove_vocab_limit, hd_glove_wv_limit, hd_glove_w2i_limit = limit_vocab(hd_glove_wv, hd_glove_w2i, hd_glove_vocab, exclude=gender_specific)\n",
    "#dbl_glove_vocab_limit, dbl_glove_wv_limit, dbl_glove_w2i_limit = limit_vocab(dbl_glove_wv, dbl_glove_w2i, dbl_glove_vocab, exclude=gender_specific)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get most biased words\n",
    "he_vector = glove_wv[glove_w2i['he'], :]\n",
    "she_vector = glove_wv[glove_w2i['she'], :]\n",
    "biased_words = compute_word_bias(glove_wv_limit, glove_w2i_limit, glove_vocab_limit, he_vector, she_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision 1.0\n",
      "precision 1.0\n",
      "precision 0.9995\n"
     ]
    }
   ],
   "source": [
    "# cluster using limited vocabulary\n",
    "for n in [100, 500, 1000]:\n",
    "    my_cluster(glove_wv_limit, glove_w2i_limit, 1, glove_vocab_limit, biased_words, num_biased_words=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard Debias Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision 0.76\n",
      "precision 0.8\n",
      "precision 0.8\n"
     ]
    }
   ],
   "source": [
    "# cluster using limited vocabulary\n",
    "for n in [100, 500, 1000]:\n",
    "    my_cluster(hd_glove_wv_limit, hd_glove_w2i_limit, 1, hd_glove_vocab_limit, biased_words, num_biased_words=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Hard Debiase Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision 1.0\n",
      "precision 1.0\n",
      "precision 0.9995\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# cluster using limited vocabulary\n",
    "for n in [100, 500, 1000]:\n",
    "    my_cluster(dbl_glove_wv_limit, dbl_glove_w2i_limit, 1, dbl_glove_vocab_limit, biased_words, num_biased_words=n)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Analogy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from web.evaluate import evaluate_on_semeval_2012_2\n",
    "from web.datasets.analogy import fetch_msr_analogy\n",
    "from web.evaluate import evaluate_analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build word dictionary\n",
    "glove_dict = {}\n",
    "for word in glove_vocab:\n",
    "    glove_dict[word] = glove_wv[glove_w2i[word], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_results = evaluate_on_semeval_2012_2(glove_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17252551510397837\n"
     ]
    }
   ],
   "source": [
    "print(glove_results['all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset created in /Users/ericaustin/web_data/analogy/EN-MSR\n",
      "\n"
     ]
    }
   ],
   "source": [
    "msr_data = fetch_msr_analogy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing 410 words. Will replace them with mean vector\n",
      "/opt/anaconda3/lib/python3.8/site-packages/web-0.0.1-py3.8.egg/web/analogy.py:105: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  A, B, C = np.vstack(w.get(word, mean_vector) for word in X_b[:, 0]), \\\n",
      "/opt/anaconda3/lib/python3.8/site-packages/web-0.0.1-py3.8.egg/web/analogy.py:106: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  np.vstack(w.get(word, mean_vector) for word in X_b[:, 1]), \\\n",
      "/opt/anaconda3/lib/python3.8/site-packages/web-0.0.1-py3.8.egg/web/analogy.py:107: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  np.vstack(w.get(word, mean_vector) for word in X_b[:, 2])\n"
     ]
    }
   ],
   "source": [
    "glove_analogy_results = evaluate_analogy(glove_dict, msr_data['X'], msr_data['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.446375\n"
     ]
    }
   ],
   "source": [
    "print(glove_analogy_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard Debias Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build word dictionary\n",
    "hd_glove_dict = {}\n",
    "for word in hd_glove_vocab:\n",
    "    hd_glove_dict[word] = hd_glove_wv[hd_glove_w2i[word], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd_glove_results = evaluate_on_semeval_2012_2(hd_glove_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17629261126785614\n"
     ]
    }
   ],
   "source": [
    "print(hd_glove_results['all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing 410 words. Will replace them with mean vector\n"
     ]
    }
   ],
   "source": [
    "hd_glove_analogy_results = evaluate_analogy(hd_glove_dict, msr_data['X'], msr_data['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.511625\n"
     ]
    }
   ],
   "source": [
    "print(hd_glove_analogy_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from web.evaluate import evaluate_categorization\n",
    "from web.datasets.categorization import fetch_BLESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "bless_data = fetch_BLESS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/web-0.0.1-py3.8.egg/web/evaluate.py:88: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  words = np.vstack(w.get(word, mean_vector) for word in X.flatten())\n"
     ]
    }
   ],
   "source": [
    "glove_cat_results = evaluate_categorization(glove_dict, bless_data['X'], bless_data['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81\n"
     ]
    }
   ],
   "source": [
    "print(glove_cat_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/web-0.0.1-py3.8.egg/web/evaluate.py:88: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  words = np.vstack(w.get(word, mean_vector) for word in X.flatten())\n"
     ]
    }
   ],
   "source": [
    "hd_glove_cat_results = evaluate_categorization(hd_glove_dict, bless_data['X'], bless_data['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84\n"
     ]
    }
   ],
   "source": [
    "print(hd_glove_cat_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
